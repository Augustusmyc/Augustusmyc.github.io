<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=gb2312">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:宋体;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:等线;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"等线 Light";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:NimbusRomNo9L-Regu;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:"\@宋体";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@等线";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@等线 Light";}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:等线;}
h1
	{mso-style-link:"标题 1 字符";
	margin-top:17.0pt;
	margin-right:0cm;
	margin-bottom:16.5pt;
	margin-left:0cm;
	text-align:justify;
	text-justify:inter-ideograph;
	line-height:240%;
	page-break-after:avoid;
	font-size:22.0pt;
	font-family:等线;
	font-weight:bold;}
h2
	{mso-style-link:"标题 2 字符";
	margin-top:13.0pt;
	margin-right:0cm;
	margin-bottom:13.0pt;
	margin-left:0cm;
	text-align:justify;
	text-justify:inter-ideograph;
	line-height:173%;
	page-break-after:avoid;
	font-size:16.0pt;
	font-family:"等线 Light";
	font-weight:bold;}
h3
	{mso-style-link:"标题 3 字符";
	margin-top:13.0pt;
	margin-right:0cm;
	margin-bottom:13.0pt;
	margin-left:0cm;
	text-align:justify;
	text-justify:inter-ideograph;
	line-height:173%;
	page-break-after:avoid;
	font-size:16.0pt;
	font-family:等线;
	font-weight:bold;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{mso-style-link:"页眉 字符";
	margin:0cm;
	margin-bottom:.0001pt;
	text-align:center;
	layout-grid-mode:char;
	border:none;
	padding:0cm;
	font-size:9.0pt;
	font-family:等线;}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{mso-style-link:"页脚 字符";
	margin:0cm;
	margin-bottom:.0001pt;
	layout-grid-mode:char;
	font-size:9.0pt;
	font-family:等线;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{mso-style-link:"标题 字符";
	margin-top:12.0pt;
	margin-right:0cm;
	margin-bottom:3.0pt;
	margin-left:0cm;
	text-align:center;
	font-size:16.0pt;
	font-family:"等线 Light";
	font-weight:bold;}
p
	{margin-right:0cm;
	margin-left:0cm;
	font-size:12.0pt;
	font-family:宋体;}
span.1
	{mso-style-name:"标题 1 字符";
	mso-style-link:"标题 1";
	font-weight:bold;}
span.a
	{mso-style-name:"标题 字符";
	mso-style-link:标题;
	font-family:"等线 Light";
	font-weight:bold;}
span.2
	{mso-style-name:"标题 2 字符";
	mso-style-link:"标题 2";
	font-family:"等线 Light";
	font-weight:bold;}
span.3
	{mso-style-name:"标题 3 字符";
	mso-style-link:"标题 3";
	font-weight:bold;}
span.a0
	{mso-style-name:"页眉 字符";
	mso-style-link:页眉;}
span.a1
	{mso-style-name:"页脚 字符";
	mso-style-link:页脚;}
.MsoChpDefault
	{font-family:等线;}
 /* Page Definitions */
 @page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	layout-grid:15.6pt;}
div.WordSection1
	{page:WordSection1;}
-->
</style>

</head>

<body bgcolor="#BBDFBB" lang=ZH-CN style='text-justify-trim:punctuation'>

<div class=WordSection1 style='layout-grid:15.6pt'>

<p class=MsoTitle><span style='font-size:22.0pt'>利用机器学习，将不等式转变为神经网络</span></p>

<p class=MsoNormal align=center style='text-align:center'>作者：马悦驰（<span
lang=EN-US>Yue-Chi Ma</span>）</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal style='text-indent:21.0pt'>最近让我博士毕业的那篇文章终于正式发表了（杂志名称：<span
lang=EN-US>nature partner journal quantum information</span>），鉴于文章很长但核心思想理解起来不难，我打算写一个面向公众的详细的中文介绍。文章把机器学习和量子力学（量子信息）进行交叉研究，但读懂中文介绍不要求读者掌握机器学习和量子力学的任何知识。只要求读者学过</p>

<p class=MsoNormal style='text-indent:21.0pt'><span lang=EN-US>1 </span>高中数学，文理科均可【看懂核心内容】</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2 </span>学过大学本科线性代数，知道矩阵乘法、特征值、特征态、<span
lang=EN-US>Trace</span>等概念；知道欧拉公式<span lang=EN-US>e<sup>i</sup></span><sup>θ </sup><span
lang=EN-US>= cos</span>θ<span lang=EN-US> + i sin</span>θ【看懂全部内容】</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>在原文标题中，“不等式”是“贝尔不等式”（量子力学的概念）。但实际上它的应用范围并不限于量子力学，所以中文介绍里去掉了这个字眼。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<h2><span lang=EN-US>0 </span>物理背景</h2>

<p class=MsoNormal style='text-indent:21.0pt'>纠缠态<span lang=EN-US>(entangled
state)</span>是量子力学预言的一种叠加态，最早是为了批判量子力学所蕴含的哲学思想，而由爱因斯坦等三名科学家于<span lang=EN-US>1935</span>年首先提出的概念。它起初被称为<span
lang=EN-US>EPR</span>佯谬，后来薛定谔首先提出了“纠缠”的术语。</p>

<p class=MsoNormal style='text-indent:21.0pt'>量子力学预言，当两个粒子纠缠在一起时，测量其中一个，那么另一个粒子的状态会在同一瞬间发生改变，即使二者相隔非常远。换言之，测量这一操作的“影响”传递速度是无穷大。爱因斯坦觉得这种“幽灵般的超距作用”不应该存在，量子力学理论是有问题的（不完备）。</p>

<p class=MsoNormal style='text-indent:21.0pt'>为了验证爱因斯坦的想法，约翰<b>・</b>贝尔于<span
lang=EN-US>1964</span>年提出了一种实验方案，后来演化出了多种版本。简单地说，这些方案试图将各个粒子在不同方向上的测量结果做线性组合，得到一个或多个不等式。一旦测量结果违背任意一个不等式，则可说明粒子间确实存在纠缠。这些不等式都被称作“贝尔不等式”（<span
lang=EN-US>Bell’s inequalities</span>）。</p>

<p class=MsoNormal style='text-indent:21.0pt'>此后一系列违背贝尔不等式的实验结果表明，纠缠确实存在，量子力学并没有错。</p>

<p class=MsoNormal style='text-indent:21.0pt'>如今，纠缠已成为量子信息领域的核心资源，它在量子计算，量子隐形传输和量子通讯等领域有广泛的用途。如果现在有人声称造出了一台量子计算机，那么要想得到学术界的认可，首先需要提供证据说明：这台机器的确能够生成纠缠态。</p>

<p class=MsoNormal style='text-indent:21.0pt'>关于纠缠，至今很多基础问题仍然没有解决。一般地，给定量子系统的所有信息（密度矩阵），判断它们是否纠缠在一起，就是一个尚未被完全解决的难题，即使系统最多只有<span
lang=EN-US>3</span>个粒子纠缠在一起。以下未经特殊说明，粒子都是指<span lang=EN-US>qubit. qubit</span>意味着每次测量结果只有两种可能。</p>

<p class=MsoNormal style='text-indent:21.0pt'>接下来，我们将具体介绍贝尔不等式，然后从神经网络<span
lang=EN-US>(Artificial Neural Network, ANN)</span>的角度出发，探索它与不等式之间的联系，并重新审视“纠缠态判定”这一问题。</p>

<h2><span lang=EN-US>1 </span>贝尔不等式是什么？</h2>

<p class=MsoNormal style='text-indent:21.0pt'>这里介绍贝尔不等式的一种：<span lang=EN-US>CHSH</span>不等式。假设<span
lang=EN-US>Alice</span>和<span lang=EN-US>Bob</span>手中各有一个粒子<span lang=EN-US>, </span>他们分别从两个方向对自己手中的粒子进行测量（<span
lang=EN-US>measure</span>），如下图所示：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=546 height=71 src="神经网络不等式.files/image001.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>注意这里的<span lang=EN-US>a a’</span>和<span
lang=EN-US>b b’</span>既表示测量方向，也表示测量结果。结果取值只有两种可能，记为<span lang=EN-US>+1</span>或<span
lang=EN-US>-1</span>。将测量结果拼在一起可以得到<span lang=EN-US>CHSH</span>不等式（是两个不等式，因为有两边）：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=374 height=32 id="图片 2" src="神经网络不等式.files/image002.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>如果每次测量都能得到确定的结果，那可以将四个测量结果共<span
lang=EN-US>16</span>种情况分别带进去验证，不等式全部成立。</p>

<p class=MsoNormal style='text-indent:21.0pt'>实际情况是，测量得到的结果是随机的，而且测量可能会导致被测量粒子的状态发生改变。因此在实验时，<span
lang=EN-US>Alice</span>和<span lang=EN-US>Bob</span>需要各自测量大量的粒子（成对的纠缠粒子），每个粒子只测一次（只从一个方向测），测完就扔掉。最后计算的是上述不等式的平均值（用<span
lang=EN-US>&lt;&gt;</span>表示）。</p>

<p class=MsoNormal style='text-indent:21.0pt'>只要两人离得足够远，那么根据爱因斯坦的想法，<span
lang=EN-US>Alice</span>和<span lang=EN-US>Bob</span>无论怎样操作，在较短时间内都无法影响对方的测量结果。那么，可以假定两人各自测量时结果以某种确定概率分布得到<span
lang=EN-US>1</span>或者<span lang=EN-US>-1</span>。但不管概率分布长什么样子，结果都应该满足贝尔不等式，因为对于每一种特定情况都满足，它们的平均值当然也满足。</p>

<p class=MsoNormal style='text-indent:21.0pt'>然而实验结果却违背了贝尔不等式！这样一来就说明了一点，<span
lang=EN-US>Alice</span>和<span lang=EN-US>Bob</span>的粒子即使相隔非常远，彼此之间也能影响对方。这种影响的传递速度超越了光速（非局域性）。</p>

<p class=MsoNormal style='text-indent:21.0pt'>为了让读者理解什么叫超距作用，这里举一个例子。我们不妨假设，<span
lang=EN-US>Alice</span>比<span lang=EN-US>Bob</span>先测，<span lang=EN-US>Alice</span>测量<span
lang=EN-US>a</span>或<span lang=EN-US>a’</span>时永远得到<span lang=EN-US>1</span>，<span
lang=EN-US>Bob</span>测量<span lang=EN-US>b</span>时也永远得到<span lang=EN-US>1. </span>但当<span
lang=EN-US>Alice</span>测量<span lang=EN-US>a</span>时，<span lang=EN-US>Bob</span>手里对应的粒子会在同一瞬间“感应到”这个测量，并将<span
lang=EN-US>b’</span>设为<span lang=EN-US>-1</span>（超距作用），<span lang=EN-US>Alice</span>测量<span
lang=EN-US>a’</span>时，<span lang=EN-US>b’</span>会设为<span lang=EN-US>1</span>，这样<span
lang=EN-US>ab-ab’+a’b+a’b’=4</span>，违背了贝尔不等式！</p>

<p class=MsoNormal style='text-indent:21.0pt'>当然，这个例子并不真实，这里只是为了方便读者理解“超距作用会导致违背贝尔不等式”而提出的假想情况。</p>

<p class=MsoNormal style='text-indent:21.0pt'>无论读者能否理解这一节的内容，只需记住：贝尔不等式提供了一种实验方案，实验结果违背它则可确定“超距作用<span
lang=EN-US>”</span>的存在。用量子力学的语言来说，违背贝尔不等式意味着粒子的波函数是纠缠态，反之则无法确定其是否纠缠。不纠缠的态称为可分态（<span
lang=EN-US>separable states</span>）<span lang=EN-US>.</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=178 src="神经网络不等式.files/image003.jpg"></span></p>

<h2><span lang=EN-US>2 </span>神经网络是什么？</h2>

<p class=MsoNormal align=center style='text-align:center;text-indent:21.0pt'><span
lang=EN-US>&nbsp;<img width=554 height=264 id="图片 5"
src="神经网络不等式.files/image004.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>这里以单隐藏层神经网络（上图左边）为例，它分为输入层（<span
lang=EN-US>Input Layer</span>），隐藏层<span lang=EN-US>(Hidden Layer)</span>和输出层<span
lang=EN-US>(Output Layer)</span>三个部分。网络节点（图右）所做的事情，是一个带权重的加法操作，后跟一个非线性的激活（<span
lang=EN-US>activate</span>）函数。隐藏层的非线性操作必须有，否则前后两个线性变化可以简化为一个，那该节点也失去了存在的意义。</p>

<p class=MsoNormal style='text-indent:21.0pt'>下面来看一个没有隐藏层的神经网络，也被称作感知机（<span
lang=EN-US>perceptron</span>），见下图。</p>

<p class=MsoNormal align=center style='text-align:center;text-indent:21.0pt'><span
lang=EN-US><img width=436 height=235 id="图片 6" src="神经网络不等式.files/image005.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>在输出层中我们使用了<span lang=EN-US>sigmoid</span>函数，将一个实数对应到<span
lang=EN-US>0-1</span>之间，根据其是否小于<span lang=EN-US>0.5</span>将输入分为两类，这个数有时被解释为概率。当然，就算不加<span
lang=EN-US>sigmoid</span>函数，一样可以根据输出值是否小于<span lang=EN-US>0</span>来分类。加它只是为了便于后面训练。接下来所有的神经网络，输出层都会有<span
lang=EN-US>sigmoid</span>函数，不再另作说明。</p>

<h2><span lang=EN-US>3 </span>神经网络与不等式的联系</h2>

<p class=MsoNormal style='text-indent:21.0pt'>感知机与单个不等式是等价的模型，或者说不等式可以编码到感知机上，如下图所示：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=562 height=208 id="图片 7" src="神经网络不等式.files/image006.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>这里不等式的权重，即<span lang=EN-US>1 -1 1
1 2</span>对应于感知机的权重。这里只写了<span lang=EN-US>CHSH</span>不等式的一半。输出小于<span
lang=EN-US>0</span>（<span lang=EN-US>sigmoid</span>输出小于<span lang=EN-US>0.5</span>）则确定是纠缠态，反之则无法确认是否纠缠。</p>

<p class=MsoNormal style='text-indent:21.0pt'>根据之前的介绍，贝尔不等式有多种形式。光是<span
lang=EN-US>CHSH</span>不等式就可以写出多个变种来（比如将不等式种<span lang=EN-US>aa’ </span>对调，<span
lang=EN-US>bb’ </span>对调）。只要违背其中之一就可以确认是纠缠态。那这些不等式能否一次性编码到一个神经网络中呢？答案是肯定的，只需要加上隐藏层。</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=553 height=241 id="图片 11" src="神经网络不等式.files/image007.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>如上图所示，这里只画了<span lang=EN-US>4</span>个贝尔不等式（图左），它们可以编码到<span
lang=EN-US>4</span>个隐藏单元（图右）上。每个单元处理一个不等式。</p>

<p class=MsoNormal style='text-indent:21.0pt'>隐藏层的激活函数一律采用<span lang=EN-US>ReLU
(Rectified Linear Units</span>，可译作修正线性单元，线性整流函数、斜坡函数等<span lang=EN-US>)</span>。如上图所示，在遵守所有不等式的情况下，每一个隐藏单元输出<span
lang=EN-US>0</span>。反之，见下图：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=234 id="图片 12" src="神经网络不等式.files/image008.jpg"></span></p>

<p class=MsoNormal>相应的隐藏单元输出违背贝尔不等式的值，从而影响到最终输出。</p>

<h2><span lang=EN-US>4 </span>神经网络的通用性<span lang=EN-US> &amp; </span>量子力学简介</h2>

<p class=MsoNormal style='text-indent:21.0pt'>到此为止，我们说明了如何将任意多个不等式编码到一个神经网络上，从而将“遵守所有不等式”和“违背至少一个不等式”的输入分成两类。实际上，量子力学预言，在所有特定（如<span
lang=EN-US>2-qubit</span>）系统中<span lang=EN-US>, </span>对于每一个纠缠态，都存在一个不等式<span
lang=EN-US>(</span>被称为<span lang=EN-US>witness inequality), </span>使该纠缠态违背它，而所有可分态都遵守它。所有的不等式都依赖于一组固定的测量方向。因此，只要隐藏层足够大，单层神经网络原则上可将所有可分态和任意多组纠缠态区分开，只需在每一个隐藏单元和输入层的连接上编码一个<span
lang=EN-US>witness</span>不等式。</p>

<p class=MsoNormal style='text-indent:21.0pt'>本节接下来的内容都是为了说清楚上述这个结论。我会介绍一些量子力学和量子信息的知识，要求读者至少学过基本的线性代数。如果看不懂，没有关系，不会影响后面内容的理解；如果读者很熟悉这章的内容，快速浏览一遍即可。</p>

<p class=MsoNormal style='text-indent:21.0pt'>首先，我们需要给纠缠态下一个明确的定义。量子力学用密度矩阵ρ来描述系统的状态，如果矩阵能分解成下面这种形式：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=510 height=73 id="图片 14" src="神经网络不等式.files/image009.jpg"></span></p>

<p class=MsoNormal>则称该系统是“可分态”（确切地说叫“完全可分态”），反之，则是纠缠态。式子左边是整个系统的密度矩阵，这里<span
lang=EN-US>sep</span>是<span lang=EN-US>separable</span>（可分）的缩写。<span
lang=EN-US>n</span>是粒子数。式子右边的ρ<sub><span lang=EN-US>i</span></sub>是每一个粒子的密度矩阵，它们以一定概率<span
lang=EN-US>p<sub>i</sub></span>处于密度矩阵ρ<sub><span lang=EN-US>i</span></sub>描述的状态上，<span
style='font-size:11.0pt;font-family:"MS Gothic"'>&#8855;</span>是<span lang=EN-US>Kronecker</span>符号，表示求张量积。对于<span
lang=EN-US>qubit</span>系统，每一个ρ<sub><span lang=EN-US>i</span></sub>的大小为<span
lang=EN-US>2</span>×<span lang=EN-US>2</span>，整个系统的密度矩阵大小为<span lang=EN-US>2<sup>n</sup></span>×<span
lang=EN-US>2<sup>n</sup>.</span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>可以证明，违背贝尔不等式的态一定是纠缠态，但并不是所有的纠缠态都能找到一个能够违背的贝尔不等式。我们将违背贝尔不等式的态称作非局域态（<span
lang=EN-US>non-local states</span>）<span lang=EN-US>,</span>它们是纠缠态的真子集。读者可以理解为，贝尔不等式本身是独立于量子力学的理论，违背贝尔不等式说明了“超距作用”的存在性，但并不是所有纠缠态的物理性质都必须靠“超距作用”才能解释。</p>

<p class=MsoNormal style='text-indent:21.0pt'>那么，能不能像非局域态那样，对于每一个纠缠态都找到一种不等式，使得该纠缠态违背这个不等式，而所有可分态都遵守这个不等式呢<span
lang=EN-US>? </span>答案是肯定的（证明略）。这样的不等式被称作<span lang=EN-US>witness</span>不等式。之前说的贝尔不等式可以看作<span
lang=EN-US>witness</span>不等式的特例。</p>

<p class=MsoNormal style='text-indent:21.0pt'><span lang=EN-US>witness</span>的全称是<span
lang=EN-US>entanglement witness, </span>它是一个厄密矩阵<span lang=EN-US>W. “</span>厄密<span
lang=EN-US>”</span>表示自身和它转置取共轭之后相等。在量子力学中，厄密矩阵和“测量”操作是一一对应的关系，矩阵的本征值表示可能的测量结果。当且仅当<span
lang=EN-US>W</span>满足以下条件时可以称作<span lang=EN-US>witness:</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=380 height=79 id="图片 8" src="神经网络不等式.files/image010.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>这里ρ<sub><span
lang=EN-US>sep</span></sub>和ρ<sub><span lang=EN-US>ent</span></sub>分别表示可分态和纠缠态，此时称ρ<sub><span
lang=EN-US>ent</span></sub>被检测（<span lang=EN-US>detect</span>）到了。<span
lang=EN-US>Tr</span>是<span lang=EN-US>Trace, Tr(</span>ρ<span lang=EN-US>W) </span>表示在特定系统ρ下用<span
lang=EN-US>W</span>观测结果的平均值，也可写作<span lang=EN-US>&lt;W&gt;. </span>任意的厄密矩阵（大小确定）都可以写成一组有限且固定的厄密矩阵（基矩阵）线性相加的形式：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=224 height=94 id="图片 13" src="神经网络不等式.files/image011.jpg"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>对于<span lang=EN-US>qubit</span>系统，σ是单位矩阵以及<span
lang=EN-US>x,y,z</span>方向上的<span lang=EN-US>Pauli</span>矩阵。这里不给<span
lang=EN-US>Pauli</span>矩阵的定义，读者只需要记住这三个<span lang=EN-US>Pauli</span>矩阵的物理含义可以理解成<span
lang=EN-US>x,y,z</span>三个方向的测量操作就行，单次测量结果不是<span lang=EN-US>1</span>就是<span
lang=EN-US>-1</span>。总而言之，包括<span lang=EN-US>witness</span>在内的任意测量操作（厄密矩阵）都可以写成不等式的形式：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=434 height=63 id="图片 15" src="神经网络不等式.files/image012.jpg"></span></p>

<p class=MsoNormal>之前<span lang=EN-US>CHSH</span>不等式中的<span lang=EN-US>a a’ b
b’</span>在量子力学中都是<span lang=EN-US>Pauli</span>矩阵的形式，但它们的测量方向一般不正交。</p>

<p class=MsoNormal style='text-indent:21.0pt'>用来描述量子系统的密度矩阵ρ也是一个厄密矩阵，但还需要额外满足两个条件，<span
lang=EN-US>1 </span>ρ的所有本征值非负（半正定），<span lang=EN-US>2 </span>ρ的所有本征值和为<span
lang=EN-US>1</span>。这里ρ的本征值的物理含义是：系统处于对应本征态上的经典概率。 当系统完全未知，或者说完全不清楚密度矩阵形式的时候，实验上一般通过在“基矩阵”上做测量取平均值的方式来确定密度矩阵的所有参数，这一操作被称作<span
lang=EN-US>Tomography. </span>以<span lang=EN-US>2-qubit</span>系统为例：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=510 height=194 id="图片 18" src="神经网络不等式.files/image013.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>Alice</span>和<span lang=EN-US>Bob</span>每人手里拥有粒子对中的一个（有大量这样的粒子对），分别从<span
lang=EN-US>x, y, z</span>三个方向进行测量，然后将结果两两求张量积，就能确定密度矩阵中的所有参数了，这里一共有<span
lang=EN-US>15</span>个自由参数。<span lang=EN-US>I</span>是单位矩阵，物理意义为“无论怎么测量，结果一律是<span
lang=EN-US>1</span>”<span lang=EN-US>.</span></p>

<p class=MsoNormal style='text-indent:21.0pt'>如果读者看到这里还没有晕，那接下来的结论就简单了，根据<span
lang=EN-US>witness</span>完备性定理，每一个纠缠态ρ<sub><span lang=EN-US>ent</span></sub><span
lang=EN-US>, </span>都存在一个<span lang=EN-US>witness</span>检测到它。</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=474 height=214 id="图片 19" src="神经网络不等式.files/image014.jpg"></span></p>

<p class=MsoNormal>每一个<span lang=EN-US>witness</span>都是一个不等式，只需要将所有的不等式按前述的方法全部编码到神经网络上就可以了。网络的输入是“基矩阵”的测量结果平均值，或者说<span
lang=EN-US>Tomography. </span>而权重则是每一个<span lang=EN-US>witness</span>写成不等式后的权重<span
lang=EN-US>w.</span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<h2><span lang=EN-US>5 </span>机器学习不等式</h2>

<p class=MsoNormal>然而现在有两个问题：</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-US>1) </span>虽然理论上编码<span lang=EN-US>witness</span>后，能够得到一个通用的纠缠<span
lang=EN-US>-</span>可分态分类器神经网络，但我们并不知道怎么去寻找<span lang=EN-US>witness</span>，只是知道它理论上存在。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-US>2) </span>原则上无穷多个<span lang=EN-US>witness</span>，或者说有无穷多个隐藏单元的神经网络可以将所有纠缠态和所有可分态全部区分开。能不能用有限个隐藏单元以较高概率做到这一点？这听起来像是要画足够多的直线框一个圆一样，似乎可行，但具体怎么操作？说到底还是怎么找<span
lang=EN-US>witness</span>的问题。</p>

<p class=MsoNormal style='text-indent:21.0pt'>这两个问题引出了本文的另一个主题：机器学习。它是近两年很火的人工智能背后的核心技术。机器学习的核心思想是试图通过以往经验或数据去自动改进模型参数，它有三个主要分支：有监督学习（<span
lang=EN-US>supervised learning</span>）<span lang=EN-US>, </span>无监督学习（<span
lang=EN-US>unsupervised learning</span>）和增强学习（<span lang=EN-US>reinforcement
learning</span>）。这里仅涉及有监督学习的内容，它是目前最成熟，工业界使用最广泛的机器学习方法。</p>

<p class=MsoNormal style='text-indent:21.0pt'>所谓有监督学习，本质上是一种函数拟合方法（绝大部分情况如此），换了个高大上的说法而已。假设我们拥有大量已知的数据集：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=534 height=56 id="图片 40" src="神经网络不等式.files/image015.jpg"></span></p>

<p class=MsoNormal>试图去训练（寻找）一个函数<span lang=EN-US>f</span>，使得<span lang=EN-US>y=f(x)</span>尽可能成立，这就是有监督学习的过程。在我们的问题中<span
lang=EN-US>f</span>是神经网络的模型，学习过程就是去调整神经网络的权重。比如，对于感知机：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=398 height=160 id="图片 22" src="神经网络不等式.files/image016.jpg"></span></p>

<p class=MsoNormal>一般地，<span lang=EN-US>x</span>是一个向量，组成<span lang=EN-US>x</span>的元素被称作“特征”<span
lang=EN-US>(features). </span>理想输出<span lang=EN-US>y</span>被称作“标签<span
lang=EN-US>”</span>（<span lang=EN-US>label</span>）<span lang=EN-US>. </span>在我们的问题中，<span
lang=EN-US>x</span>是密度矩阵ρ，特征指ρ在所有矩阵基上测得的结果平均值<span lang=EN-US>, </span>在<span
lang=EN-US>n-qubit</span>系统共有<span lang=EN-US>4<sup>n</sup>-1</span>个特征。<span
lang=EN-US>y</span>有两种取值，分别表示相应的密度矩阵是纠缠态（记为<span lang=EN-US>0</span>）或可分态（记为<span
lang=EN-US>1</span>）。</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=452 height=129 id="图片 41" src="神经网络不等式.files/image017.jpg"></span></p>

<p class=MsoNormal>我们定义二元交叉熵代价函数（<span lang=EN-US>binary cross entropy cost
function</span>）<span lang=EN-US>:</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=456 height=91 id="图片 16" src="神经网络不等式.files/image018.jpg"></span></p>

<p class=MsoNormal>其中<span lang=EN-US>a</span>为神经元实际输出，<span lang=EN-US>y</span>是标签。<span
lang=EN-US>N</span>是总数据量。代价函数非负，所谓“学习”，其实就是调整神经网络权重，使得代价函数尽可能小，或者说让<span
lang=EN-US>a</span>的取值尽可能接近<span lang=EN-US>y. </span>这一过程一般是用梯度下降法、牛顿法，或者它们的变种来完成的。例如著名的反向传播算法，其实就是梯度下降在神经网络上的特例。在网络上能找到很多详细介绍，这里就不做说明了。</p>

<p class=MsoNormal style='text-indent:21.0pt'>一般来说，机器学习只关注能否找到一组参数，使得模型（神经网络）的输出尽可能接近理想的输出，至于参数的意义并不重要。这里我们采用机器学习的方法，但目的是得到近似<span
lang=EN-US>witness</span>不等式的参数，这和传统的机器学习不太一样。</p>

<p class=MsoNormal style='text-indent:21.0pt'>接下来还有一个重要问题，如何获取标签？我们刚才提到，找到了<span
lang=EN-US>witness</span>就能确认是纠缠态，但现在我们并不清楚<span lang=EN-US>witness</span>是否存在以及如何去找，所以只能用别的方法去得到标签，这也是有监督学习的局限性，必须有足够带标签的数据，才能去训练模型。看到这里也许有人会问，如果有办法得到标签，那为什么还要用有监督学习训练呢？答案是，获取标签的方法本身是困难的，可能必须要通过人来完成。如果这些以前必须靠人力完成任务可以由机器来做，这当然是有意义的，比如，给一个人脸数据库和一张人脸照片，判断照片上的人是数据库里的谁，这在以前是很难靠机器来完成的，现在可以靠机器学习来做到。</p>

<p class=MsoNormal style='text-indent:21.0pt'>回到我们的问题中来，对于<span lang=EN-US>2-qubit</span>系统，知道密度矩阵的前提下，可以通过<span
lang=EN-US>Positive Partial Transpose (</span>以下简称<span lang=EN-US>PPT) </span>判据来判断是否纠缠，首先，求该矩阵在某个子系统中偏转置的最小本征值λ<sub><span
lang=EN-US>min</span></sub>：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=280 height=47 id="图片 17" src="神经网络不等式.files/image019.jpg"></span></p>

<p class=MsoNormal>λ<sub><span lang=EN-US>min</span></sub>小于<span lang=EN-US>0</span>时系统一定是纠缠态（这对任意系统都成立，可以根据可分态的定义直接证明，因为密度矩阵的转置仍然是密度矩阵），而λ<sub><span
lang=EN-US>min</span></sub>大于或等于<span lang=EN-US>0</span>时一定是可分态（对<span
lang=EN-US>2-qubit</span>系统成立）。顺带一提，对于纠缠态，λ<sub><span lang=EN-US>min</span></sub>的绝对值也被叫做负度（<span
lang=EN-US>negativity</span>），是衡量纠缠度大小的指标之一。</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=360 height=118 id="图片 23" src="神经网络不等式.files/image020.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>有了打标签的方法，接下来是数据采集。我们采用标准的方法生成大量的随机密度矩阵ρ<sub><span
lang=EN-US>rand</span></sub>：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=308 height=126 id="图片 4" src="神经网络不等式.files/image021.jpg"></span></p>

<p class=MsoNormal>这里的σ是指每个元素实部虚部都服从正态分布的随机矩阵。</p>

<p class=MsoNormal style='text-indent:21.0pt'>用这种方法，我们生成<span lang=EN-US>3,000,000</span>个随机密度矩阵（维度为<span
lang=EN-US>4</span>×<span lang=EN-US>4</span>），通过<span lang=EN-US>PPT</span>计算λ<sub><span
lang=EN-US>min</span></sub>，其分布如下图所示：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=302 height=269 id="图片 20" src="神经网络不等式.files/image022.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>可以发现，大部分的λ<sub><span
lang=EN-US>min</span></sub>都集中在<span lang=EN-US>0</span>附近，这意味着大部分数据都处于纠缠态和可分态的边缘地带，大约<span
lang=EN-US>1/4</span>的数据为可分态，<span lang=EN-US>3/4</span>的数据为纠缠态。为了使参与训练的纠缠态<span
lang=EN-US>-</span>可分态数量相等，我们仅采用红色区域的数据进行模型的训练（<span lang=EN-US>train</span>）。之后按相同方法重新生成<span
lang=EN-US>300,000</span>个随机矩阵，全部用于测试（<span lang=EN-US>test</span>），即检验模型的好坏。测试结果如下图所示（本文出现的所有正确<span
lang=EN-US>/</span>错误率（<span lang=EN-US>accuracy/error rate</span>）均为测试集上的结果）：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=184 id="图片 25" src="神经网络不等式.files/image023.jpg"></span></p>

<p class=MsoNormal>蓝色和绿色分别代表纠缠态和可分态。左图表明，随着隐藏层加大，二者的正确率都会有所提高。必须指出的是，一个正确率的指标是不足以反映出分类器的好坏，因为正确率很大程度上取决于数据本身是否处于纠缠态和可分态的边缘处。为了体现这一点，我们画了右图，考察不同的λ<sub><span
lang=EN-US>min</span></sub>与错误率的关系，并发现大部分情况下只有当λ<sub><span lang=EN-US>min</span></sub>处于<span
lang=EN-US>0</span>附近时（即纠缠<span lang=EN-US>-</span>可分态的边缘处）才会出错。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>以上结果表明，采用机器学习训练通用纠缠<span
lang=EN-US>-</span>可分态分类器是可行的，不过上述结果并没有说明机器学习的优势，毕竟<span lang=EN-US>PPT</span>可以做到完美，而机器学习只能无限接近完美。但是别忘了，我们的目的，是要训练<span
lang=EN-US>witness</span>不等式。据我们所知，目前并没有方法能够在<span lang=EN-US>2-qubit</span>系统下完成以下任务：寻找足够多的<span
lang=EN-US>witness</span>，将所有可分态和所有纠缠态区分开。能否用机器学习的方法（至少近似地）做到这一点呢？答案是肯定的，接下来我们以<span
lang=EN-US>10000</span>个隐藏层的模型为例来说明这一点。</p>

<p class=MsoNormal style='text-indent:21.0pt'>首先，回顾一下前面说的神经网络。若每一个输入为<span
lang=EN-US>x, </span>隐藏层<span lang=EN-US>x<sub>1</sub></span>可以用以下公式计算：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=320 height=37 id="图片 10" src="神经网络不等式.files/image024.jpg"></span></p>

<p class=MsoNormal>这里σ<sub><span lang=EN-US>RL</span></sub>是针对每一个神经元的<span
lang=EN-US>ReLU </span>函数。最终输出为<span lang=EN-US>y:</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=316 height=41 id="图片 24" src="神经网络不等式.files/image025.jpg"></span></p>

<p class=MsoNormal>这里的σ<sub><span lang=EN-US>S</span></sub>是<span lang=EN-US>sigmoid</span>函数</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=323 height=40 id="图片 27" src="神经网络不等式.files/image026.jpg"></span></p>

<p class=MsoNormal>根据之前的编码过程，只要<span lang=EN-US>W<sub>2</sub></span>的所有神经元都是负数，就可以让纠缠态违背的所有不等式都导致输出减小。如果<span
lang=EN-US>W<sub>2</sub></span>的某一个神经元等于<span lang=EN-US>0</span>，那么它对应的不等式可以去掉，因为对输出无影响。当然，这并不是说神经元是正数<span
lang=EN-US>(</span>假设是<span lang=EN-US>q)</span>就不可以，因为编码一个同样的不等式和<span
lang=EN-US>-q</span>的<span lang=EN-US>W<sub>2</sub></span>神经元就可以将它抵消掉。</p>

<p class=MsoNormal style='text-indent:21.0pt'>那么，训练得到的<span lang=EN-US>W<sub>2</sub></span>的分布又如何呢？让我们画一个直方图来分析一下：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=248 id="图片 28" src="神经网络不等式.files/image027.jpg"></span></p>

<p class=MsoNormal>可以看出，和我们之前的编码一致。大部分都是负数。这里有很多神经元（元素）几乎为<span lang=EN-US>0</span>，从量子信息的角度看，这意味着该模型还有进一步压缩的空间。从机器学习的视角来看，这是所谓的<span
lang=EN-US>Dead ReLU Problem</span>，因为很多隐藏神经元根本没被激活，是<span lang=EN-US>ReLU </span>的问题。</p>

<p class=MsoNormal>我们把大于<span lang=EN-US>-0.1</span>的神经元的直方图标记为橙色。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>再来看看隐藏层<span
lang=EN-US>x<sub>1</sub></span>输出的平均值。根据之前的编码过程，对于可分态，该值为<span lang=EN-US>0</span>，而纠缠态则大于<span
lang=EN-US>0</span>。训练的结果很好地匹配了这一点：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=237 id="图片 29" src="神经网络不等式.files/image028.jpg"></span></p>

<p class=MsoNormal>这里上图是所有隐藏神经元<span lang=EN-US>x<sub>1</sub></span>的平均值，下图是去掉橙色神经元（<span
lang=EN-US>W<sub>2</sub></span>元素大于<span lang=EN-US>-0.1</span>）后<span
lang=EN-US>x<sub>1</sub></span>的平均值。后者更能体现“可分态为<span lang=EN-US>0</span>，纠缠态大于<span
lang=EN-US>0</span>”。</p>

<p class=MsoNormal style='text-indent:21.0pt'>上述结果说明，机器学习到的“不等式”从数值上看确实具有<span
lang=EN-US>witness</span>不等式的特点。</p>

<h2><span lang=EN-US>5* </span>“编码”想法的来历</h2>

<p class=MsoNormal style='text-indent:21.0pt'>在这篇文章中，我先阐述了“如何编码”，再说机器学习的“训练结果”。而真实的故事其实是反过来的。当初我训练过多种神经网络模型，当隐藏层采用<span
lang=EN-US>sigmoid</span>或者<span lang=EN-US>tanh</span>作为激活函数时，正确率只有<span
lang=EN-US>90%</span>多一点，多加几个隐藏层或者加长训练时间也无济于事。而当激活函数换成<span lang=EN-US>ReLU</span>后，正确率有明显提升。确切地说，训练时正确率会先较快地达到<span
lang=EN-US>90%</span>左右，之后开始缓慢地提升。</p>

<p class=MsoNormal style='text-indent:21.0pt'>这促使我思考为什么会这样。从机器学习的视角看，讨论<span
lang=EN-US>ReLU</span>的优势时一般会提到“梯度消失”的现象。大致意思是，采用<span lang=EN-US>sigmoid</span>或者<span
lang=EN-US>tanh</span>作为多层神经网络隐藏层激活函数时，每次通过计算出的梯度来更新权重，那么越靠前的层会更新的值会越小，而<span
lang=EN-US>ReLU</span>可以克服这一点。</p>

<p class=MsoNormal style='text-indent:21.0pt'>但我们采用的神经网络只有一层，这个说法就站不住脚了。这促使我思考，既然研究的是量子信息的问题，那能不能从量子信息的角度给一个解释呢？这才有了“编码”不等式的想法。采用<span
lang=EN-US>ReLU</span>时，区分纠缠<span lang=EN-US>-</span>可分态的神经网络模型可以解释成多个<span
lang=EN-US>witness</span>，而<span lang=EN-US>tanh</span>和<span lang=EN-US>sigmoid</span>看起来不具备这一特点。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<h2><span lang=EN-US>6 </span>机器学习的优势</h2>

<p class=MsoNormal style='text-indent:21.0pt'>作为通用纠缠<span lang=EN-US>-</span>可分量子态分类器，采用有监督学习训练出的神经网络可以看作是<span
lang=EN-US>witness</span>不等式的组合，这是神经网络特有的性质。但除此之外，对于判定量子态任务本身，机器学习相对于传统方法的优势有哪些？能不能把这些优势推广到更一般的量子态分类问题上？</p>

<p class=MsoNormal style='text-indent:21.0pt'>机器学习最广为人知的优势在于“解放人力”，如果一件任务需要靠人脑的重复劳动来完成，那么有监督学习就有可能派上用场。通常机器完成任务的速度会快很多。可是，在我们的问题中，<span
lang=EN-US>PPT</span>已经足够快了，机器学习相对于<span lang=EN-US>PPT</span>还有优势吗<span
lang=EN-US>? </span>接下来，我们将从<span lang=EN-US>PPT</span>的缺点出发来探讨这一问题。</p>

<p class=MsoNormal style='text-indent:21.0pt'><span lang=EN-US>PPT</span>判据最明显的缺陷在于，需要先用<span
lang=EN-US>Tomography</span>得到密度矩阵，然后才能进行偏转置和求最小本征值的计算，而<span lang=EN-US>Tomography</span>需要通过测量得到<span
lang=EN-US>4<sup>n</sup>-1</span>个特征，这是一项非常消耗测量资源的操作。那么，有没有可能只用一部分特征，就能完美区分所有的纠缠态和可分态呢？答案是否定的（<span
lang=EN-US>PRL 116</span>，<span lang=EN-US>230501</span>（<span lang=EN-US>2016</span>））。因此，作为通用纠缠<span
lang=EN-US>-</span>可分态分类器，原则上包括机器学习在内的所有方法都无法做到节省测量资源。但是，对于一些特定情况，测量资源是完全有可能降下来的。我们举几个例子来说明这一点。</p>

<p class=MsoNormal><b><span lang=EN-US style='font-size:11.0pt'>&nbsp;</span></b></p>

<p class=MsoNormal><b><span lang=EN-US style='font-size:11.0pt'>6.1</span></b><b><span
style='font-size:11.0pt'>转换<span lang=EN-US>CHSH</span>不等式为态分类器</span></b></p>

<p class=MsoNormal style='text-indent:21.0pt'>考虑如下密度矩阵：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=460 height=77 src="神经网络不等式.files/image029.jpg"></span></p>

<p class=MsoNormal>这类态在我们的论文里被称作 “<span lang=EN-US>test-run</span>”态。可以通过<span
lang=EN-US>PPT</span>判据解析地算出λ<sub><span lang=EN-US>min</span></sub></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=491 height=39 id="图片 30" src="神经网络不等式.files/image030.jpg"></span></p>

<p class=MsoNormal>从几何的角度来说，该密度矩阵的每一个态，对应于<span lang=EN-US>Bloch</span>球面（<span
lang=EN-US>p=1</span>）或球内<span lang=EN-US>(p&lt;1)</span>的每一个点，其中蓝色部分是可分态，其余为纠缠态：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=314 height=341 id="图片 31" src="神经网络不等式.files/image031.jpg"></span></p>

<p class=MsoNormal>对于这样一种态，<span lang=EN-US>CHSH</span>不等式是无法完美区分纠缠<span
lang=EN-US>-</span>可分态的，如果采用一组固定的测量基</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=508 height=47 id="图片 32" src="神经网络不等式.files/image032.jpg"></span></p>

<p class=MsoNormal>在θ<span lang=EN-US>=</span><span lang=EN-US>π</span><span
lang=EN-US>/2</span>时，可以算出<span lang=EN-US>p&gt;1/3</span>为纠缠态，<span
lang=EN-US>p</span>≤<span lang=EN-US>1/3</span>为可分态。<span lang=EN-US>CHSH</span>的准确率大概是这个样子（纵坐标是<span
lang=EN-US>ф</span>取不同值的平均错误率，这里<span lang=EN-US>ф</span>均匀分布于<span lang=EN-US>[0,2π]</span>）：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=553 height=193 id="图片 49" src="神经网络不等式.files/image033.jpg"></span></p>

<p class=MsoNormal>在<span lang=EN-US>p</span>∈<span lang=EN-US>(1/sqrt(2), 1]</span>时，只有一部分能成功，这是因为预先不知道<span
lang=EN-US>ф</span>的值，从而无法通过调整系数或测量角度，使得<span lang=EN-US>CHSH</span>不等式刚好探测到这个纠缠态。<span
lang=EN-US>p</span>∈<span lang=EN-US>(1/3, 1/sqrt(2)] </span>时<span lang=EN-US>CHSH</span>不等式完全失效，此时无论怎么调整系数或者测量角度都是行不通的。</p>

<p class=MsoNormal style='text-indent:21.0pt'>这里顺带一提，有一种<span lang=EN-US>witness</span>专门用来探测这种类型的纠缠态（<span
lang=EN-US>Journal of Modern Optics, 2003, Gühne et al.</span>），但依然会有不知道<span
lang=EN-US>ф</span>而无法确定测量角度的问题。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>那么，能否用和<span
lang=EN-US>CHSH</span>不等式相同数量的测量资源，利用机器学习来做到区分这种类型的纠缠<span lang=EN-US>-</span>可分态呢？答案是肯定的，先来看θ<span
lang=EN-US>=</span><span lang=EN-US>π</span><span lang=EN-US>/2</span>上的情况：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=363 height=269 id="图片 26" src="神经网络不等式.files/image034.jpg"></span></p>

<p class=MsoNormal>图中<span lang=EN-US>CHSH<sub>ml</sub>(</span>蓝色线条<span
lang=EN-US>)</span>是指用不含隐藏层的<span lang=EN-US>perception</span>的训练结果，而<span
lang=EN-US>Bell<sub>ml</sub>(</span>黑色线条<span lang=EN-US>)</span>是用含隐藏层的神经网络的训练结果。<span
lang=EN-US>Bell<sub>ml</sub></span>括号内的数字表示<span lang=EN-US>2 qubits, 4</span>个特征，<span
lang=EN-US>150</span>个隐藏层。完整的结果见下图（图中蓝色，绿色代表可分态和纠缠态）：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=228 height=220 id="图片 47" src="神经网络不等式.files/image035.jpg"><img
width=311 height=221 id="图片 48" src="神经网络不等式.files/image036.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>几种模型形式的对比：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=521 height=196 id="图片 46" src="神经网络不等式.files/image037.jpg"></span></p>

<p class=MsoNormal>以上结论说明了，对于这类特殊的量子态，通过训练带隐藏层的神经网络，我们能够使用和<span lang=EN-US>CHSH</span>不等式形式一样的测量资源（<span
lang=EN-US>4</span>个特征，每人两个测量角度。远少于<span lang=EN-US>PPT</span>），得到近乎完美的区分纠缠态和可分态的分类器。但要注意，之所以<span
lang=EN-US>CHSH</span>（以及<span lang=EN-US>witness</span>，还有一般意义下的<span
lang=EN-US>PPT</span>判据也是）做不到这一点，原因之一是这类标准方法有一个“充分不必要”的限制，即：必须要将所有真实的可分态（包括不属于“<span
lang=EN-US>test-run</span>”态的类型）判定为“可分态”才可以。而我们用机器学习训练的类贝尔不等式分类器<span
lang=EN-US>(Bell-like Predictor) </span>则不受此限制。画成示意图如下：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=464 height=193 id="图片 52" src="神经网络不等式.files/image038.jpg"></span></p>

<p class=MsoNormal>为了更公平地和标准方法比较，接下来的试验中，我们的训练和测试集会尽量覆盖所有的纠缠和可分态。也就是尽可能变成下面这样：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=264 height=172 id="图片 53" src="神经网络不等式.files/image039.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal><b><span lang=EN-US style='font-size:11.0pt'>6.2 </span></b><b><span
style='font-size:11.0pt'>多<span lang=EN-US>qubit</span>系统下节省资源</span></b></p>

<p class=MsoNormal><b><span lang=EN-US style='font-size:11.0pt'>&nbsp;</span></b></p>

<p class=MsoNormal>接下来让我们考察多<span lang=EN-US>qubit</span>系统，首先必须指出，多<span
lang=EN-US>qubit</span>纠缠的种类比<span lang=EN-US>2 qubit</span>复杂得多。我们这里只关注<span
lang=EN-US>n-qubit GHZ</span>态：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=380 height=46 id="图片 54" src="神经网络不等式.files/image040.jpg"></span></p>

<p class=MsoNormal>因为它有一个性质，任选其中<span lang=EN-US>n-1</span>个粒子组成的系统都不纠缠，但<span
lang=EN-US>n</span>个粒子放在一起就纠缠了，这是很多类型的纠缠态（如<span lang=EN-US>W </span>态）都没有的性质。因此使用<span
lang=EN-US>PPT</span>判据时，需要把<span lang=EN-US>GHZ</span>态和完全可分态区分开，只能把整个系统的密度矩阵都测出来才可以判断。当<span
lang=EN-US>n</span>较大时，这非常消耗测量资源。</p>

<p class=MsoNormal style='text-indent:21.0pt'>接下来我们来做这样一件事，以上述<span lang=EN-US>GHZ</span>态为种子，通过随机局域酉（<span
lang=EN-US>local unitary</span>）或局域可逆（<span lang=EN-US>local invertible</span>）矩阵<span
lang=EN-US>, </span>生成大量的类<span lang=EN-US>GHZ</span>态，这些操作被称作<span lang=EN-US>LOCC</span>或<span
lang=EN-US>SLOCC</span>（对于<span lang=EN-US>SLOCC</span>最后还需要把量子态归一化，这里省略了）：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=553 height=98 id="图片 55" src="神经网络不等式.files/image041.jpg"></span></p>

<p class=MsoNormal>我们把<span lang=EN-US>LOCC</span>或<span lang=EN-US>SLOCC</span>其中一组作为我们的训练（或测试）集的一部分，标签记为<span
lang=EN-US>0. </span>然后根据定义生成大量随机的完全可分态，标签记为<span lang=EN-US>1</span>，作为训练（或测试）集的另一部分，将它们合并在一起，试图让机器去区分二者。这可以看作一个游戏，生成量子态的人知道答案，让其它人来猜。我们试图只用随<span
lang=EN-US>n</span>多项式增长的测量资源来区分二者。</p>

<p class=MsoNormal style='text-indent:21.0pt'>更具体地说，我们这样生成特征（测量矩阵）：随机生成<span
lang=EN-US>n</span>或<span lang=EN-US>2n</span>个特征（对于<span lang=EN-US>LOCC</span>是<span
lang=EN-US>n</span>个，<span lang=EN-US>SLOCC</span>是<span lang=EN-US>2n</span>个，因为后者量子态覆盖的区域更广，所以多生成一组），每个特征由<span
lang=EN-US>n</span>个在<span lang=EN-US>Bloch</span>球上均匀分布的随机方向<span lang=EN-US>Pauli</span>矩阵的张量积组成。对应的物理操作是：对于每一个<span
lang=EN-US>qubit</span>都用<span lang=EN-US>n</span>或<span lang=EN-US>2n</span>个随机方向的<span
lang=EN-US>Pauli</span>矩阵测得结果，然后将它们乘起来得到<span lang=EN-US>n</span>或<span
lang=EN-US>2n</span>个特征。</p>

<p class=MsoNormal>训练过程是很快的，结果如下：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=472 height=223 id="图片 56" src="神经网络不等式.files/image042.jpg"></span></p>

<p class=MsoNormal>可以看出，只要隐藏层取得足够大，在只用少量资源的前提下，神经网络也能够很好地区分二者。单独看<span
lang=EN-US>49</span>个隐藏神经元的结果如下：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=473 height=199 id="图片 57" src="神经网络不等式.files/image043.jpg"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal><b><span lang=EN-US style='font-size:11.0pt'>6.3 </span></b><b><span
style='font-size:11.0pt'>探测<span lang=EN-US>bound</span>纠缠态</span></b></p>

<p class=MsoNormal style='text-indent:21.0pt'>对于两粒子系统，当它们都是<span lang=EN-US>qubit</span>（<span
lang=EN-US>2 by 2</span>）的时候，<span lang=EN-US>PPT</span>判据是完美的。但对于两个粒子都是<span
lang=EN-US>qutrit (3 by 3) </span>的情况，有一部分纠缠态<span lang=EN-US>PPT</span>是无法探测的。这里<span
lang=EN-US>qutrit</span>是指测量结果有三种可能，或者说密度矩阵维度为<span lang=EN-US>3</span>×<span
lang=EN-US>3</span>的粒子。一般地，除了<span lang=EN-US>2 by 2</span>和<span lang=EN-US>2 by
3</span>的系统可以用<span lang=EN-US>PPT</span>判定，并没有一般的解析方法可以判断更高维度的纠缠态和可分态。对于多粒子体系也没有一般方法。我们把<span
lang=EN-US>PPT</span>判据无法探测的纠缠态统称为<span lang=EN-US>bound </span>纠缠态。</p>

<p class=MsoNormal style='text-indent:21.0pt'>我们首先关注<span lang=EN-US>3-qubit </span>系统下的一种特殊的<span
lang=EN-US>bound</span>纠缠态，称作<span lang=EN-US>shift UPB. </span>采用跟之前类似的方法，通过<span
lang=EN-US>SLOCC</span>生成大量<span lang=EN-US>bound</span>纠缠态，通过定义生成完全可分态。训练结果如下图：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=405 height=334 id="图片 59" src="神经网络不等式.files/image044.jpg"></span></p>

<p class=MsoNormal>这里采用的特征如下表所示，除了σ<sub><span lang=EN-US>x</span></sub><span
lang=EN-US>, </span>σ<sub><span lang=EN-US>y</span></sub><span lang=EN-US>, </span>σ<sub><span
lang=EN-US>z</span></sub>和单位矩阵<span lang=EN-US>I</span>，剩下的都是随机<span
lang=EN-US>Pauli</span>矩阵：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=554 height=163 id="图片 9" src="神经网络不等式.files/image045.jpg"></span></p>

<p class=MsoNormal>这里<span lang=EN-US>n=3. </span>从结果来看，采用<span lang=EN-US>3<sup>n</sup>
-1=26</span>个特征和<span lang=EN-US>Tomography</span>的<span lang=EN-US>4<sup>n</sup>
-1</span>个特征，效果差不多好，前者错误率约为<span lang=EN-US>1%</span>，后者几乎<span lang=EN-US>0%. </span>由此可见，对于<span
lang=EN-US>PPT</span>无法探测的纠缠态，机器学习也能在较少的资源下做得很好。</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<h2><span lang=EN-US>6* </span>机器学习<span lang=EN-US>vs SDP </span>――更快的速度</h2>

<p class=MsoNormal style='text-indent:21.0pt'>刚才我们举的例子都是专用纠缠态分类器，我们提到，在一般情况下并没有解析的方法探测纠缠态。但是，在两粒子系统下，有一种标准的数值方法可以尽可能准确地完成这一任务，这个方法被称作半正定规划（<span
lang=EN-US>Semidefinite programming, </span>简称<span lang=EN-US>SDP</span>）。简单地说，<span
lang=EN-US>SDP</span>试图在满足一定约束条件下计算某个函数的最小值，根据这个值是否大于<span lang=EN-US>0</span>来预测是否是纠缠态。约束矩阵（维度为<span
lang=EN-US>N</span>）设置得越大，计算速度越慢但越精确。</p>

<p class=MsoNormal><span lang=EN-US>`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>很容易想到，能否用<span
lang=EN-US>SDP</span>来打标签，然后通过机器学习更快速地做到这一点？答案是肯定的。这部分内容我暂未发表，但我可以把结果列出来：</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=416 height=277 id="图片 1" src="神经网络不等式.files/image046.png"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>这是<span lang=EN-US>2-qutrit</span>系统下的结果。这里纵坐标是平均判定一个量子态所需的时间，横坐标是错误率。蓝点表示<span
lang=EN-US>SDP</span>在不同约束下的结果，<span lang=EN-US>N</span>是约束矩阵的维度，这里假定<span
lang=EN-US>N=500</span>时错误率为<span lang=EN-US>0</span>。红点表示神经网络在随着隐藏层变化（<span
lang=EN-US>100-10000</span>个神经元）时的情况，它的预测时间比<span lang=EN-US>SDP</span>快了几个数量级。</p>

<p class=MsoNormal style='text-indent:21.0pt'>为什么神经网络会快这么多？除了因为神经网络计算过程比<span
lang=EN-US>SDP</span>简单得多（<span lang=EN-US>ANN</span>最耗时的过程也就两个线性变换而已），我想更重要的原因在于，神经网络非常容易做到大量数据“并行化”计算，而<span
lang=EN-US>SDP</span>只能用<span lang=EN-US>for</span>循环一个一个处理，这导致我当初花了一两个月的时间采集足够多的数据用于训练，而只用了不到一个上午就训练完了。</p>

<p class=MsoNormal style='text-indent:21.0pt'>那问题来了，<span lang=EN-US>SDP</span>可否做到并行化计算？我猜测可以，并相信并行化后依然会比机器学习慢。不过，这纯粹是个技术问题，因为我要毕业了，有很多杂七杂八的事情要处理，没时间跟进了而已……</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<h2><span lang=EN-US>7 </span>类似的工作</h2>

<p class=MsoNormal style='text-indent:21.0pt'>在我把我们的文章放在<span lang=EN-US>arXiv</span>上之后不久，有一篇独立完成的，类似工作的文章（<span
lang=EN-US>A Separability-Entanglement Classifier via Machine Learning</span>，<span
lang=EN-US>Sirui Lu</span>）也放了上去。这篇文章试图用别的机器学习方法训练纠缠<span lang=EN-US>-</span>可分量子态分类器。在没有输入额外先验知识（除了密度矩阵以外的信息）的前提下，它们的分类器（以<span
lang=EN-US>2-qubit</span>系统为例）错误率如下：</p>

<p class=MsoNormal align=center style='text-align:center;text-indent:21.0pt'><span
lang=EN-US><img width=418 height=135 id="图片 36" src="神经网络不等式.files/image047.png"></span></p>

<p class=MsoNormal style='text-indent:21.0pt'>他们在文中声称，这些错误率暗示了纠缠<span
lang=EN-US>-</span>可分态的边界过于复杂，很难用常规的形状描述</p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US><img
width=384 height=332 id="图片 37" src="神经网络不等式.files/image048.png"></span></p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

<p class=MsoNormal>这篇文章使用的量子态分布（密度矩阵本征值服从<span lang=EN-US style='font-size:
10.0pt;font-family:NimbusRomNo9L-Regu'>Dirichlet</span><span style='font-size:
10.0pt'>分布</span>）和我用的不一样。我使用了和他们同样的方法生成大量的量子态，用我们文章的模型和方法训练，错误率能降到<span
lang=EN-US>2%</span>以下。</p>

<h2><span lang=EN-US>8 </span>总结<span lang=EN-US> &amp; </span>我们的贡献</h2>

<p class=MsoNormal style='text-indent:21.0pt'>本文讨论了如何利用有监督学习的方法，将神经网络训练为纠缠<span
lang=EN-US>-</span>可分量子态分类器。这种方法也可以用于训练其它量子态分类器。</p>

<p class=MsoNormal style='text-indent:21.0pt'>我们首先论述了如何利用单隐藏层神经网络来刻画输入是否违背多组线性不等式中的至少一个。据我所知，有不少数学问题都可以转化为这种问题，但我不知道数学上对它有没有什么统一的称呼。</p>

<p class=MsoNormal style='text-indent:21.0pt'>考虑到任意纠缠态都存在至少一个它所违背的<span
lang=EN-US>witness</span>不等式，我们实际上说明了神经网络作为纠缠<span lang=EN-US>-</span>可分态分类器的通用性。我们首次提出：可以利用机器学习来寻找<span
lang=EN-US>witness</span>，从而描述纠缠<span lang=EN-US>-</span>可分态的分界面，并给出了结果。</p>

<p class=MsoNormal style='text-indent:21.0pt'>我们接下来探讨了利用机器学习来节省测量资源的可能性，并给出了几个例子。对于那些<span
lang=EN-US>PPT</span>判据很难或无法探测的纠缠态，神经网络可以用更少的测量资源把它们和完全可分态区分开。</p>

<p class=MsoNormal style='text-indent:21.0pt'>最后我们指出，对于需要使用<span lang=EN-US>SDP</span>这种速度较慢的数值方法的问题（如判定纠缠态），可以考虑通过<span
lang=EN-US>SDP</span>来打标签，用机器学习训练，从而得到速度明显比<span lang=EN-US>SDP</span>快得多的模型。</p>

</div>

</body>

</html>
